{"title":"Analyzing Political Polarization: Topic Modelling","slug":"political-topic-centrality-2","emoji":"üèõ","blurb":"Part two of three in a series that analyzes political polarization through network science. Modelling and extracting topics from political tweets. Posted on the popular blog Towards Data Science.","type":"bp","tags":["nlp"],"link":"<a aria-label='Blog' href='https://medium.com/@cameronraymond/analyzing-political-polarization-topic-modelling-2-b45a7bd3d3cc'>Blog</a>","date":"May 21, 2020","prod":true,"html":"<img src=\"https://cdn-images-1.medium.com/max/2402/1*8wo8S9TmNx7aMHWSW_lSfg.png\" alt=\"Source: [Salesforce.com](https://www.salesforce.com/ca/blog/2019/10/get-to-know-ai-for-business--natural-language-processing.html)\"><em>Source: <a href=\"https://www.salesforce.com/ca/blog/2019/10/get-to-know-ai-for-business--natural-language-processing.html\">Salesforce.com</a></em>\n<p>Networks can tell us a lot about the world we live in. As Duncan Watts, a UPenn sociologist, famously said: &quot;Networks are important because if we don‚Äôt understand networks, we can‚Äôt understand how markets function, organizations solve problems or how societies change.&quot; However, if we‚Äôre exploring relationships between different <strong>things</strong> through networks, we need to understand <strong>what exactly those things are.</strong> That is what we‚Äôll be looking at in this article: what can we say about the tweets leading up to the Canadian 2019 election that can help our network analysis of political polarization?</p><p><a href=\"https://towardsdatascience.com/analyzing-political-polarization-on-twitter-engagement-graphs-aa0614ed1361\">Previously</a>, I laid out the foundation for this analysis. I argued that political polarization is important to study, but is a broad and vague term ‚Äî so a more concrete task is to formalize/quantify the different forms that political tweets can take. I argued that there are two broad types of political messages that are relevant to political polarization: <em>bridging messages</em>, that attract engagement from new, untapped demographics ‚Äî and <em>bonding messages</em>, which rally a political party‚Äôs voter base. And I introduced engagement graphs, which are networks that frame the tweets of political parties as brokers between the party leaders and the broader electorate. However, to understand how different political messages affected the election, we have to know what types of topics the party leaders tweeted about!</p><img src=\"https://cdn-images-1.medium.com/max/5894/1*q8LjOscOt3U-PXajSNqusA.png\" alt=\"\">\n<p>This article, then, is about the tweets scraped from the Twitter accounts of the five party leaders we‚Äôre looking at: Andrew Scheer, Elizabeth May, Jagmeet Singh, Justin Trudeau, and Maxime Bernier. We‚Äôll look at how to clean Twitter data, how to model it, and by the end we‚Äôll be able to take each tweet in our engagement graph and assign it a topic.</p><h2 id=\"the-data\">The Data</h2>\n<p>This new data set was collected with Twitter‚Äôs historical search API, which allows user‚Äôs to programmatically access any publicly available tweet. The API was used to collect all of the English tweets from Canada‚Äôs five, English speaking party leaders: Andrew Scheer, Elizabeth May, Jagmeet Singh, Justin Trudeau, and Maxime Bernier. All of these party leaders‚Äô tweets between October 21, 2018 and October 21, 2019 ‚Äî Canada‚Äôs 43 general election ‚Äî were collected. While the tweets from each Federal party‚Äôs official Twitter accounts were also collected, they acted as logistical tools ‚Äî informing party affiliates of events and rallies. The personal accounts for party leaders better represent their beliefs, platforms and style of rhetoric, and are better suited to analyze the bridging versus bonding nature of different topics. In this spirit, only tweets of the party leader were used, excluding retweets. Below graphs the daily and cumulative number of tweets over time, in aggregate and by party leader, for a total of <strong>7,978</strong> tweets.</p><img src=\"https://cdn-images-1.medium.com/max/2160/1*9Z7d9R6f0bV8WoaHlS7BWw.png\" alt=\"Party leader tweets over time.\"><em>Party leader tweets over time.</em>\n<p>Additionally, for each tweet collected from a party leader, all of the available retweets by general users were collected for a total of <strong>113,293 retweets</strong> by <strong>36,450 general users</strong>. This is, again, visualized in aggregate and by party leader below.</p><img src=\"https://cdn-images-1.medium.com/max/2160/1*pYkiqRx8Xso0uxkObA0bAw.png\" alt=\"Retweets for each party leader over time.\"><em>Retweets for each party leader over time.</em>\n<h2 id=\"what-is-topic-modelling\">What is Topic Modelling?</h2>\n<p>In order to evaluate the bridging and bonding characteristics of political messages on Twitter, the tweets we collected need to be organized by topic. Given that there are thousands of tweets, going through each individual one and assigning it some topic isn‚Äôt feasible or applicable to other contexts. As a result, we need techniques that autonomously organize big, unclassified bodies of text.</p><p>Topic modelling is a form of unsupervised machine learning (ML) that can find clusters of words that frequently occur together (topics), connect words with similar meanings, and can distinguish different uses of words with multiple meanings¬π. This is based on the assumption that a document, in this case a tweet, is about a finite number of things¬≤. By training a topic model on our collection of tweets, we will be able to see what words frequently occurred together, which will act as our topics.</p><h3 id=\"data-cleaning\">Data Cleaning</h3>\n<p>Given the inherent noise and extraneous info in text data, it is standard and necessary to preprocess text before modeling¬π. Since we‚Äôre only interested in what a tweet is about, we can safely remove punctuation marks; words like ‚Äòand‚Äô, ‚Äòor‚Äô, ‚Äòthe‚Äô, etc.; words with fewer than three characters; and URLs. Other common Twitter symbols like ‚ÄòRT:‚Äô, ‚Äò@‚Äô and ‚Äò#‚Äô can also be removed. Emojis contain valuable information, but are hard for a computer to interpret, so they were converted to text using the Python package emoji. After this process, all text was converted to lower-case and lemmatized to get rid of common suffixes. This means that the tweet below, after preprocessing, reads: <em>wherever maple leaf fly represents rich history bright future value hold dear happy flag day canada</em>.</p><img src=\"https://cdn-images-1.medium.com/max/2000/1*huOCrc67kdG9zn6QgMktVA.png\" alt=\"Example tweet\"><em>Example tweet</em>\n<h3 id=\"latent-dirichlet-allocation\">Latent Dirichlet Allocation</h3>\n<p>My original paper, which can be found on my <a href=\"https://cameronraymond.me/\">personal website</a>, goes into depth on what a latent Dirichlet allocation (LDA) is. But I think it‚Äôs important to not get too bogged down in other academics‚Äô (brilliant) work and distract from what we‚Äôre trying to achieve: <em>a knowledge of the main topics Canadian party leaders tweeted about in the lead up to the 2019 election.</em> So for this section I will stay at a pretty high level. An LDA is a topic model that defines two probability distributions‚Äî one which models topics as ‚Äúa distribution over a fixed vocabulary of terms,‚Äù and another which models documents as a distribution of topics¬≤. The LDA requires four inputs: the body of text ‚Äî which in this context are the cleaned tweets from all five party leaders; Œ± ‚Äî which acts as a concentration parameter for how documents are modeled as topics; Œ≤ ‚Äî which acts as a concentration parameter for how topics are modeled as words; and <em>k</em>‚Äî which is the number of topics to be modeled¬≤. By concentration parameter I mean that when Œ± is small, a tweet is more likely to be considered an even mix of the <em>k</em> topics; conversely when Œ± is larger a tweet is more likely to be considered ‚Äòabout‚Äô fewer topics. By training an LDA on all ~8,000 cleaned tweets, we will be able to <em>model each tweet as some distribution of topics</em>. In doing so, we‚Äôll be able to plug those tweet topics into our engagement graph to see who tweeted about what, and how those tweets were viewed by the voting public.</p><h2 id=\"results\">Results</h2>\n<p>By performing a parameter sweep we saw that the most performant LDA had a <em>k</em> value of 7, Œ± of 0.31 and Œ≤ of 0.81. Each of the party leaders‚Äô tweets was then represented as some combination of the 7 latent topics that were extracted. By labeling each tweet as the maximum probability value in its topic distribution, each tweet was given a single topic! I found the best way to visualize what each topic is about is to create word clouds, which I‚Äôve included below.</p><img src=\"https://cdn-images-1.medium.com/max/2088/1*OncxG28xAWVokOOY3cyJYA.png\" alt=\"LDA word clouds\"><em>LDA word clouds</em>\n<p>Topic 1 pertained to <strong>campaign messages, rallies and logistics</strong> ‚Äî and makes up 8.2% of all tweets. Topic 2 contains tweets regarding a <strong>carbon tax, pipelines and the economy</strong> ‚Äî and makes up 16.3% of all tweets. Topic 3 contains tweets about the <strong>SNC Lavalin affair</strong>, a scandal that plagued Justin Trudeau, and tweets about corruption ‚Äî making up 18% of all tweets. Topic 4 is predominantly <strong>appeals to the middle-class and economy</strong> ‚Äî and is 29.7% of all tweets. Topic 5 contains <strong>celebratory messages</strong> about the campaign, as well as tweets regarding national holidays and days of remembrance ‚Äî and make up 15% of all tweets. Topic 6 is made up of tweets about <strong>immigration, diversity and free speech</strong> ‚Äî and makes up 11.5% of all tweets. Finally, topic 7 contains tweets regarding <strong>healthcare, abortion and pharmacare</strong>‚Äî and makes up 1% of all tweets.</p><img src=\"https://cdn-images-1.medium.com/max/2702/1*mYH2M6Zmh5Sa60T5xGHbAw.png\" alt=\"Tweets by topic breakdown\"><em>Tweets by topic breakdown</em>\n<p>This is already a rich source of information. By doing this topic modelling we can see that while topic 6, tweets pertaining to diversity and immigration, only made up 11.5% of all tweets they <em>made up the majority of Maxime Bernier‚Äôs</em>. Additionally, Andrew Scheer and Elizabeth May‚Äôs campaigns relied heavily on topic 3, the SNC Lavalin affair, with a disproportionate number of tweets aimed at Justin Trudeau‚Äôs handling of the scandal. It‚Äôs also clear that the more right-leaning candidates, Maxime Bernier and Andrew Scheer, had a disproportionate number of tweets pertaining to topic 2. These were tweets rebutting Justin Trudeau‚Äôs plan to implement a carbon tax, and arguing for greater access to Alberta‚Äôs Oil Sands. Now that we know what these topics are about, we can update the engagement graph from before. Now each tweet vertex is colored according to its topic. The topics have the same color as the pie chart above for reference.</p><img src=\"https://cdn-images-1.medium.com/max/6000/1*dlDjeRQMuZoexm-onCcAuw.png\" alt=\"Engagement graph with tweet vertices colored by topic.\"><em>Engagement graph with tweet vertices colored by topic.</em>\n<h2 id=\"whats-next\">What‚Äôs Next?</h2>\n<p>Descriptive measures show the frequency that tweets of different topics were promoted by Canadian party leaders leading up to a major election. This article shows how this can be done in an autonomous way, letting topics emanate from the tweets collected. However, knowing that Maxime Bernier tweeted an absurd amount about immigration says little about how different policies rallied groups of existing supporters, or bridged different voting blocs. That is what we‚Äôll cover in the final installment of this series when we look at the concept of <em>vertex centrality.</em> I view these first two articles as somewhat disjoint, the first spent the whole time talking about the importance of networks, and then we barely mention them here. Next week will reconcile the two, and show how topic modelling is a key stepping-stone that gives real depth to the engagement graph ‚Äî and allows us to see which of these 7 topics bonded voting groups, and which bridged them.</p><p>[1]: Alghamdi, Rubayyi, &amp; Alfalqi, Khalid. (2015). A survey of topic modeling in text mining. <em>Int. j. adv. comput. sci. appl.(ijacsa)</em>, 6(1).</p><p>[2]: Blei, David M, Ng, Andrew Y, &amp; Jordan, Michael I. (2003). Latent dirichlet allocation. <em>Journal of machine learning research</em>, 3(Jan), 993‚Äì1022.</p><p>[3]: Sapul, Ma Shiela C, Aung, Than Htike, &amp; Jiamthapthaksin, Rachsuda. (2017). Trending topic discovery of twitter tweets using clustering and topic modeling algorithms. <em>Pages 1‚Äì6 of: 2017 14th international joint conference on computer science and software engineering (jcsse)</em>. IEEE.</p>"}