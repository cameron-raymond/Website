<!DOCTYPE html> <html lang=en> <head> <link href="https://fonts.googleapis.com/css?family=Mukta|Poppins:500,600&display=swap" rel=stylesheet> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <link href=global.css rel=stylesheet> <link href=manifest.json rel=manifest crossorigin=use-credentials> <link href=favicon.png rel=icon type=image/png> <link href=client/main.3898572404.css rel=stylesheet><link href=client/[slug].3f331e1e.css rel=stylesheet><link href=client/client.e75a9efc.css rel=stylesheet><link href=client/Tag.2ddad0a9.css rel=stylesheet> <noscript id=sapper-head-start></noscript><title>🧠Do Neural Networks Ever Forget? - Cameron Raymond🧠</title><link href=https://cameronraymond.me/blog/right-to-be-forgotten-ml/ rel=canonical><meta content="How machine learning throws a wrench in the 'right to be forgotten.' Bringing in some of the latest computational research on privacy, this post examines how the principles of GDPR collide with the realities of neural networks." name=description><meta content="Cameron Raymond, University of Oxford, Oxford University, Data
    Science, Social Data Sience, Data Scientist" name=keywords><meta content=website property=og:type><meta content=https://cameronraymond.me/blog/right-to-be-forgotten-ml/ property=og:url><meta content="🧠Do Neural Networks Ever Forget? - Cameron Raymond🧠" property=og:title><meta content="How machine learning throws a wrench in the 'right to be forgotten.' Bringing in some of the latest computational research on privacy, this post examines how the principles of GDPR collide with the realities of neural networks." name=og:description><meta content=https://cameronraymond.me/networkd.png property=og:image><meta content=summary property=twitter:card><meta content=https://cameronraymond.me/blog/right-to-be-forgotten-ml/ property=twitter:url><meta content="🧠Do Neural Networks Ever Forget? - Cameron Raymond🧠" property=twitter:title><meta content="How machine learning throws a wrench in the 'right to be forgotten.' Bringing in some of the latest computational research on privacy, this post examines how the principles of GDPR collide with the realities of neural networks." property=twitter:description><meta content=https://cameronraymond.me/networkd.png property=twitter:image><noscript id=sapper-head-end></noscript> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-133541363-2"></script> <script> window.dataLayer = window.dataLayer || []
      function gtag() {
        dataLayer.push(arguments)
      }
      gtag('js', new Date())

      gtag('config', 'UA-133541363-2') </script> </head> <body> <div id=sapper> <div class="svelte-ex3z1i margin"></div> <form action=https://tinyletter.com/cjkraymond class="svelte-ex3z1i sign-up-banner" method=post onsubmit="window.open('https://tinyletter.com/cjkraymond', 'popupwindow',
  'scrollbars=yes,width=800,height=600');return true" target=popupwindow><p><label class="svelte-ex3z1i label" for=tlemail>Let's be pals:</label></p> <div class=signup-input><input class="svelte-ex3z1i email" name=email id=tlemail placeholder=my@email.com></div> <input class=svelte-ex3z1i name=embed type=hidden value=1> <span class="svelte-ex3z1i tooltip"><input class="svelte-ex3z1i subscribe" type=submit value=✉️> <span class="svelte-ex3z1i tooltiptext">Subscribe!</span></span> <span class=svelte-ex3z1i id=close-sub><svg class=svelte-c8tyih viewBox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M331.3 308.7L278.6 256l52.7-52.7c6.2-6.2 6.2-16.4 0-22.6-6.2-6.2-16.4-6.2-22.6 0L256 233.4l-52.7-52.7c-6.2-6.2-15.6-7.1-22.6 0-7.1 7.1-6 16.6 0 22.6l52.7 52.7-52.7 52.7c-6.7 6.7-6.4 16.3 0 22.6 6.4 6.4 16.4 6.2 22.6 0l52.7-52.7 52.7 52.7c6.2 6.2 16.4 6.2 22.6 0 6.3-6.2 6.3-16.4 0-22.6z"></path> <path d="M256 76c48.1 0 93.3 18.7 127.3 52.7S436 207.9 436 256s-18.7 93.3-52.7 127.3S304.1 436 256 436c-48.1 0-93.3-18.7-127.3-52.7S76 304.1 76 256s18.7-93.3 52.7-127.3S207.9 76 256 76m0-28C141.1 48 48 141.1 48 256s93.1 208 208 208 208-93.1 208-208S370.9 48 256 48z"></path></svg></span></form> <nav class=svelte-1otdzf2><a aria-label=Home href=. class=svelte-1otdzf2 rel=prefetch>Cameron Raymond </a> <div class="svelte-1otdzf2 links"><a aria-label=Resume href=cameron-raymond-resume.pdf class=svelte-1otdzf2 target=_blank><span class="svelte-1otdzf2 icon hideIcons"><svg class=svelte-c8tyih viewBox="0 0 576 512" xmlns=http://www.w3.org/2000/svg><path d="M552 64H88c-13.255 0-24 10.745-24 24v8H24c-13.255 0-24 10.745-24 24v272c0 30.928 25.072 56 56 56h472c26.51 0 48-21.49 48-48V88c0-13.255-10.745-24-24-24zM56 400a8 8 0 0 1-8-8V144h16v248a8 8 0 0 1-8 8zm236-16H140c-6.627 0-12-5.373-12-12v-8c0-6.627 5.373-12 12-12h152c6.627 0 12 5.373 12 12v8c0 6.627-5.373 12-12 12zm208 0H348c-6.627 0-12-5.373-12-12v-8c0-6.627 5.373-12 12-12h152c6.627 0 12 5.373 12 12v8c0 6.627-5.373 12-12 12zm-208-96H140c-6.627 0-12-5.373-12-12v-8c0-6.627 5.373-12 12-12h152c6.627 0 12 5.373 12 12v8c0 6.627-5.373 12-12 12zm208 0H348c-6.627 0-12-5.373-12-12v-8c0-6.627 5.373-12 12-12h152c6.627 0 12 5.373 12 12v8c0 6.627-5.373 12-12 12zm0-96H140c-6.627 0-12-5.373-12-12v-40c0-6.627 5.373-12 12-12h360c6.627 0 12 5.373 12 12v40c0 6.627-5.373 12-12 12z"></path></svg></span> <span class="svelte-1otdzf2 hideLinks">Resume</span></a> <a aria-label=Blog href=blog/ class=svelte-1otdzf2 rel=prefetch aria-current=page><span class="svelte-1otdzf2 icon hideIcons"><svg class=svelte-c8tyih viewBox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"></path></svg></span> <span class="svelte-1otdzf2 hideLinks">Blog</span></a> <a aria-label=About href=about/ class=svelte-1otdzf2 rel=prefetch><span class="svelte-1otdzf2 icon hideIcons"><svg class=svelte-c8tyih viewBox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><path d="M224 256c70.7 0 128-57.3 128-128S294.7 0 224 0 96 57.3 96 128s57.3 128 128 128zm89.6 32h-16.7c-22.2 10.2-46.9 16-72.9 16s-50.6-5.8-72.9-16h-16.7C60.2 288 0 348.2 0 422.4V464c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48v-41.6c0-74.2-60.2-134.4-134.4-134.4z"></path></svg></span> <span class="svelte-1otdzf2 hideLinks">About</span></a> <div class="svelte-1otdzf2 divider"></div> <a aria-label=LinkedIn href=https://www.linkedin.com/in/CJKRaymond/ class="svelte-1otdzf2 icon"><svg class=svelte-c8tyih viewBox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></a> <a aria-label=twitter href=https://twitter.com/CJKRaymond class="svelte-1otdzf2 icon"><svg class=svelte-c8tyih viewBox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a></div></nav> <main class=svelte-y41jpk> <div></div> </main> <div class="svelte-16irf4m chat"><div></div></div> <div class="svelte-16irf4m footer"><p class=svelte-16irf4m><span aria-hidden=false aria-label=Emoji role=img>👨‍🎨</span> + <span aria-hidden=false aria-label=Emoji role=img>👷‍♂️</span> by me <br> Last updated <a aria-label="April
      06, 21" href=https://www.onthisday.com/events/April/06>April 06, '21</a></p> <div class="svelte-16irf4m links"><a aria-label=LinkedIn href=https://www.linkedin.com/in/CJKRaymond/ class="svelte-16irf4m icon"><svg class=svelte-c8tyih viewBox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></a> <div class="svelte-16irf4m divider"></div> <a aria-label=twitter href=https://twitter.com/CJKRaymond class="svelte-16irf4m icon"><svg class=svelte-c8tyih viewBox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a> <div class="svelte-16irf4m divider"></div> <a aria-label=Github href=https://github.com/cameron-raymond/ class="svelte-16irf4m icon"><svg class=svelte-c8tyih viewBox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a> <div class="svelte-16irf4m divider"></div> <a aria-label=Medium href=https://medium.com/@cameronraymond/ class="svelte-16irf4m icon"><svg class=svelte-c8tyih viewBox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M71.5 142.3c.6-5.9-1.7-11.8-6.1-15.8L20.3 72.1V64h140.2l108.4 237.7L364.2 64h133.7v8.1l-38.6 37c-3.3 2.5-5 6.7-4.3 10.8v272c-.7 4.1 1 8.3 4.3 10.8l37.7 37v8.1H307.3v-8.1l39.1-37.9c3.8-3.8 3.8-5 3.8-10.8V171.2L241.5 447.1h-14.7L100.4 171.2v184.9c-1.1 7.8 1.5 15.6 7 21.2l50.8 61.6v8.1h-144v-8L65 377.3c5.4-5.6 7.9-13.5 6.5-21.2V142.3z"></path></svg></a></div></div> <a aria-label=" " href=blog/ class=svelte-1i4fw52>blog</a> <a aria-label=" " href=sitemap.xml class=svelte-1i4fw52>sitemap</a></div> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,null,{post:{title:"Do Neural Networks Ever Forget?",slug:"right-to-be-forgotten-ml",emoji:"🧠",blurb:"How machine learning throws a wrench in the 'right to be forgotten.' Bringing in some of the latest computational research on privacy, this post examines how the principles of GDPR collide with the realities of neural networks.",type:"bp",tags:["pl"],link:"\u003Ca aria-label='Blog' href='https:\u002F\u002Fmedium.com\u002F@cameronraymond\u002F5046530eb844?source=friends_link&sk=dbfc72d8c7f3173d8496d3b5ab0e3243'\u003EBlog\u003C\u002Fa\u003E",date:"Jun. 4, 2020",prod:true,html:"\u003Cimg src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F2000\u002F1*pmSFu6KWJGdl3ZJcA_6Q8A.png\" alt=\"Unintended Feature Leakage from Gender Classification. Source: [Melis, Luca, et al.](https:\u002F\u002Fieeexplore.ieee.org\u002Fabstract\u002Fdocument\u002F8835269\u002F?casa_token=xWJF2Qn5p04AAAAA:8onczj50twpsKTaybecxy-CIAIgSRoWJ5NeJ9p0hMw53pP3t5JHJjkjpeF7wd4FLRZzd9XgnoFw)\"\u003E\u003Cem\u003EUnintended Feature Leakage from Gender Classification. Source: \u003Ca href=\"https:\u002F\u002Fieeexplore.ieee.org\u002Fabstract\u002Fdocument\u002F8835269\u002F?casa_token=xWJF2Qn5p04AAAAA:8onczj50twpsKTaybecxy-CIAIgSRoWJ5NeJ9p0hMw53pP3t5JHJjkjpeF7wd4FLRZzd9XgnoFw\"\u003EMelis, Luca, et al.\u003C\u002Fa\u003E\u003C\u002Fem\u003E\n\u003Cp\u003EAs the usage of data evolves, so should its regulation. Faster and faster, the digital world is embedding itself in our lives to remove friction. Tech removes friction by learning about us and how we behave as a collective, anticipating and reacting accordingly.  Think Starbucks sending you a push notification whenever you come close to one of their stores — one ad for a latte if it’s cold out, one for an iced coffee if it’s hot. This has made firms like Facebook, Amazon, Apple, Netflix, and Google some of the most valuable (\u003Cem\u003Ethe most valuable\u003C\u002Fem\u003E, bar none, if you consider how few employees they have) in history, giving them an out-sized influence on our lives. So it is important to ask: who are these firms accountable to? Or more importantly, what are the market forces that affect how we, their users, are treated? Facebook’s misuse of data with Cambridge Analytica, and Google’s \u003Ca href=\"https:\u002F\u002Fwww.wired.com\u002F2012\u002F05\u002Fgoogle-wifi-fcc-investigation\u002F\"\u003Erogue engineer\u003C\u002Fa\u003E who adapted a fleet of Street View cars to siphon often-sensitive data from private WiFi networks, have lead to reasonable concerns surrounding how much regulation is needed in tech. Unfortunately, when it comes to protecting our data, privacy legislation fails to take into account artificial intelligence (AI). Instead legislation, like the EU’s General Data Protection Regulation (GDPR), focuses on the explicit collection and transfer of personal information. \u003Cstrong\u003EThis ignores what makes data useful to tech firms, how it can be generalized and modeled to commodify everyday behaviour.\u003C\u002Fstrong\u003E In this way, machine learning (ML) undermines traditional privacy legislation in twice over: it complicates an our right to access and appeal how organizations use our personal information, and it ignores how ML makes implicit use of personal data.\u003C\u002Fp\u003E\u003Cp\u003EThis argument is a little more nuanced than pointing out the consequences of a world where training data can be reverse engineered, though, this is also a concern. Instead, I want to focus on what privacy legislature attempts to protect: our ability to know how companies use our data, and our ability to maintain control of our data. In doing so we’ll see that ML makes it harder to interrogate how companies  use our data. We’ll also see that correcting how our data is used in these systems is much harder than correcting the data that is protected in GDPR. Finally, I’ll make the argument that if our aim is to give greater control over how our data is used, then the right to be forgotten must also apply to ML. Otherwise, we will be ignoring what Shoshana Zuboff calls tech’s new “logic of accumulation.”² If you aren’t a fan of Zuboff, or the term “logic of accumulation” is foreign or off putting, hold on— that’s where we’ll start. To cap things off I’ll put a spotlight on some of the latest research that aims to address these problems.\u003C\u002Fp\u003E\u003Ch2 id=\"what-makes-our-data-useful\"\u003EWhat Makes Our Data Useful?\u003C\u002Fh2\u003E\n\u003Cp\u003EBefore we can understand how GDPR fails to protect \u003Cem\u003Ethe use of our data\u003C\u002Fem\u003E, we need a better understanding of what the connection is between tech firms and our personal privacy. The rapid rise of connectivity and proliferation of uses of the internet has brought about what Shoshana Zuboff considers a new technological logic of accumulation, where big data “organizes perception and shapes the expression of technological affordances at their roots.”² This is an overly academic way of saying that \u003Cem\u003Ebig data has changed how we view the world — and as a result the way firms, like Google, operate is fundamentally different from non-data oriented  firms.\u003C\u002Fem\u003E Private organizations are able to gain a deep knowledge of our online interactions “from above”, anonymously monitoring everyday behaviour to model and exploit whatever information they can gleam². Through continuous data mining and analysis, the Google’s and Facebook’s of our world are able to understand how we behave at a tremendously granular level⁸. The digital bread crumbs we leave behind are collected, stored and then aggregated and modeled to better target, personalize, and enforce. This is what researchers refer to as “the commodification of everyday behaviour.”² Tech act as indifferent observers who spread their “free” products as widely as possible, to model our behaviour for the benefit of advertisers, insurers, \u003Cem\u003Eetc.\u003C\u002Fem\u003E This digital-\u002Fdata-first process has produced relatively small firms, with fewer fixed costs, that generate tremendous amounts of wealth. And thanks to the unique corporate structures of \u003Ca href=\"https:\u002F\u002Fwww.vox.com\u002Ftechnology\u002F2018\u002F11\u002F19\u002F18099011\u002Fmark-zuckerberg-facebook-stock-nyt-wsj\"\u003EFacebook\u003C\u002Fa\u003E and Google, the ability to leverage those assets are often directed by one or two people.\u003C\u002Fp\u003E\u003Cp\u003EThe onus lies on policy makers to ensure that technology’s advances are brought about in an equitable way. A holistic privacy policy is necessary; legislation must allow for the fair, transparent collection of data, as well as ensure that data are processed and utilized in an equitable way. \u003Cstrong\u003EWhile tech firms require near ubiquitous monitoring to produce the lakes of data it feeds off of, their  true value come from the ability to process and make data useful.\u003C\u002Fstrong\u003E Given the enormity of data, this  is only made possible through ML. Theoretical and practical advances in ML let tech firms search, sort, cluster and make decisions based off subterranean patterns in data. Therefore, collection and utilization are inextricably linked. However, this is not how our privacy legislation has viewed data collection. Instead, policymakers have generally focused on the former, without recognizing how data collected is exploited implicitly in its utilization.\u003C\u002Fp\u003E\u003Ch2 id=\"what-gdpr-does-and-doesnt-do\"\u003EWhat GDPR Does (and Doesn’t) Do\u003C\u002Fh2\u003E\n\u003Cp\u003EPrivate firms — leveraging largely public datasets -– fundamentally altered the United Kingdom’s referendum to leave the EU, and the 2016 US election of Donald Trump³. In my opinion these major events are what brought questions about how our data is used into the public consciousness. Between the week’s starting April 10, 2016 and April 10, 2019, Google search interest saw increases of 119%⁴, 1,566%⁵ and 81%⁶ for the search terms: data privacy, AI ethics, and privacy software respectively. In this same timeframe, Google search interest surrounding artificial intelligence and machine learning also saw a steep uptick with corresponding 43% and 200% increases⁷. So it is not surprising that the largest piece of privacy legislation born in this political landscape, the EU’s 2016 GDPR, has been the subject of popular debate and scrutiny. \u003Cstrong\u003EGDPR regulates the processing and free movement of data, and affords individuals the “protection of [their] personal data” through three core sections: the right to informed consent, the right to access personal data, and the right to rectification and erasure\u003C\u002Fstrong\u003E⁸. GDPR gives increased protections to individuals, letting you appeal decisions made by autonomous systems. Unfortunately, by focusing on the explicit collection and movement of data it falls prey to similar flaws in earlier pieces of privacy legislature like Canada’s PIPEDA⁹. These flaws, which we’ll go into depth on, are that it can be very hard to: access our data after it’s been processed to train a neural net as well as appeal its uses given the often opaque nature of ML. As well, the right to rectification and erasure fails to take into account ML is structured by the data it’s trained on. This allows companies to profit off of our data long after we’ve requested it to be erased.\u003C\u002Fp\u003E\u003Ch3 id=\"how-do-you-fight-an-algorithm\"\u003EHow do you fight an algorithm?\u003C\u002Fh3\u003E\n\u003Cp\u003EGDPR (Article 16 specifically😉) gives us the right to appeal inaccurate collection or use of our personal data. But while the “purposes of processing” must be taken into account when rectifying inaccurate uses of data, GDPR fails to establish a litmus test for what constitutes inaccurate usage⁸. Knowing what needs to be fixed is much easier when the data in question relates to some  concrete characteristic. It’s easy to fix someones name or birthday in a database. However, in cases where an ML system makes some decision about us —  like inferring our political orientation, sexuality, or \u003Ca href=\"https:\u002F\u002Fwww.wired.com\u002Fstory\u002Fcrime-predicting-algorithms-may-not-outperform-untrained-humans\u002F\"\u003Erisk of recidivism\u003C\u002Fa\u003E— how can you appeal to a neural network? This is key because \u003Cstrong\u003Ethe data that ML is trained on are produced in an unjust world, and there is often little reason to believe that such models will do anything but replicate preexisting inequalities\u003C\u002Fstrong\u003E¹⁰. It is what researchers often refer to as algorithmic bias (which is different from statistical bias). This was the case when researchers from Microsoft and Boston University demonstrated that word embeddings can exhibit gender stereotypes to disturbing extents¹⁰. However since even supervised ML is left to its own devices to figure out how to best approximate some regression\u002Fclassification function, it is less straightforward to argue that you have been discriminated against¹¹. By placing the burden on individuals to meet this vague standard for what inaccurate usage may mean, GDPR ignores the structural biases that are easily replicated and amplified in ML¹¹.\u003C\u002Fp\u003E\u003Ch3 id=\"do-neural-networks-ever-forget\"\u003EDo Neural Networks Ever Forget?\u003C\u002Fh3\u003E\n\u003Cp\u003EGDPR deviates from previous attempts at privacy legislature by giving individuals the “right to be forgotten.” This means that if you make a request to a company that has possession of your data, they are obligated to erase it. \u003Cstrong\u003EHowever, this doesn’t extend to the ML which your data has been trained on.\u003C\u002Fstrong\u003E This is because GDPR fundamentally views data as an input to a machine that makes some decision, when actually, data shapes the decision making system itself. To me, by allowing companies to continuously profit off of our data regardless of individual preferences, this represents a fundamental flaw that ignores tech’s logic of accumulation.\u003C\u002Fp\u003E\u003Cp\u003EGDPR (Articles 17 through 20 now💃) doesn’t recognize that if your data has  been used to train a neural network, you are forever imprinted on it¹². Even if you submit an erasure request, and your information doesn’t appear in any of Facebook’s databases, your information is still implicitly being processed when Facebook decides what ad to show someone. This is what brings us back to our header image. Researchers at Cornell, UCL and the Alan Turing Institute recently demonstrated that collaborative learning models can “leak \u003Cem\u003Eunintended\u003C\u002Fem\u003E information about participants’ training data,” allowing malign actors to “infer the presence of exact data points—for example, specific locations [… as well as] \u003Cem\u003Eproperties\u003C\u002Fem\u003E that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture.”¹ This, hopefully, drives home the fact that ML is not separate from us, and there is a growing body of literature that argues our data shapes the fundamental structure of these models. In some cases, this literally means adding\u002Fdropping nodes from the layers of an ANN¹³. In framing erasure in such concrete terms, GDPR fails to remedy tech’s more exploitative characteristics and refuses to acknowledge the true utility of data: that it “records, modifies, and commodifies everyday experience.”²\u003C\u002Fp\u003E\u003Ch2 id=\"improving-the-right-to-be-forgotten\"\u003EImproving the ‘right to be forgotten’\u003C\u002Fh2\u003E\n\u003Cp\u003EGDPR gives us the right to challenge companies when they use ML to make decisions about us (what price to give, whether to insure, risk of recidivism). This is a huge step forward. Unfortunately, ML’s quality is to disappear into the background, embedding itself in our digital world. That is to say, there is rarely a big sign saying: “Watch out! A neural network is deciding whether you’re too risky to insure!” Given the embedded nature of ML, its implementation can subtly shape the online world in ways that, while technically consensual, individuals are not fully aware of. This then puts the onus on individuals to parse out their online world for inaccurate or biased systems in ways that could be far from feasible. It also ensures that only those who have the means to educate themselves on how tech\u002FML operates will be able to have full control over their data. Over the past sixteen years, there has been surprisingly little to fully address the issue of clear and informed consent.\u003C\u002Fp\u003E\u003Cp\u003EThe most overlooked aspect of privacy legislature is that there are no protections to let individuals remove themselves from models that infer from user data¹⁴. GDPR does not address the consequences of allowing tech to profit off of models, trained on our data, after we’ve invoked our “right to be forgotten.” This requires a conceptual shift in how privacy is viewed. The core of tech firms are their ability to cheaply capture data, the raw material, and model it to achieve various ends. \u003Cstrong\u003EPrivacy legislation cannot stop at the collection of data and then interpret the neural net from which it was built as something wholly different.\u003C\u002Fstrong\u003E Privacy legislation should extend to ML as well. As of now this problem is only addressed superficially in GDPR. Thankfully, researchers at the University of  Cambridge and Queen Mary University of London, among others, are proposing technical solutions to these problems. Shintre et al. proposed a novel solution that allows individual data points to be removed from artificial neural networks in their 2019 paper, \u003Cem\u003EMaking Machine Learning Forget\u003C\u002Fem\u003E¹⁵. What this demonstrates is that there are few technical obstacles to fully realizing systems where we can truly have the right to be forgotten. First however, there must be an understanding of how our data can be used and misused, and the political will to hold tech accountable.\u003C\u002Fp\u003E\u003Ch2 id=\"moving-forward\"\u003EMoving Forward\u003C\u002Fh2\u003E\n\u003Cp\u003ETechnology and ML have undoubtedly made our lives better. However, that doesn’t mean we shouldn’t be critical when tech firms unnecessarily impinge on our rights. Bezos would still be rich if we addressed these issues. In the past 20 years, the tech industry has accumulated massive amounts of user data which legislatures have subsequently had to grapple with. ML undermines the existing forms of privacy legislature in two ways. It subverts the grounds from which we can appeal inaccurate or biased uses of our personal information. As well,  problems arise when users are afforded the right to erasure without acknowledging the embedded nature of data in ML. As a result, We need a conceptual shift in how we view privacy. \u003C\u002Fp\u003E\u003Cp\u003EOur data isn’t useful by itself. Given that fact, we need to focus less on the explicit collection and transfer of data, and instead focus more on how our data is used. Our data leaves fingerprints on the neural networks they’re trained on. It’s important to remember that those fingerprints are ours as well, and as a result the right to be forgotten should extend to ML.\u003C\u002Fp\u003E\u003Cp\u003E[1]: Melis, Luca, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov. “Exploiting unintended feature leakage in collaborative learning.” In \u003Cem\u003E2019 IEEE Symposium on Security and Privacy (SP)\u003C\u002Fem\u003E, pp. 691–706. IEEE, 2019.\u003C\u002Fp\u003E\u003Cp\u003E[2]: Zuboff, Shoshana. “Big other: surveillance capitalism and the prospects of an information civilization.” \u003Cem\u003EJournal of Information Technology\u003C\u002Fem\u003E 30, no. 1 (2015): 75–89.\u003C\u002Fp\u003E\u003Cp\u003E[3]: Isaak, Jim, and Mina J. Hanna. “User data privacy: Facebook, Cambridge Analytica, and privacy protection.” \u003Cem\u003EComputer\u003C\u002Fem\u003E 51, no. 8 (2018): 57.\u003C\u002Fp\u003E\u003Cp\u003E[4]: Google Trends, “Data Privacy Search Interest (2016–2019).” Accessed on April 10, 2020. \u003Ca href=\"https:\u002F\u002Ftrends.google.com\u002Ftrends\u002Fexplore?date=2016-04-10%202020-04-10&amp;q=Data%20Privacy\"\u003Ehttps:\u002F\u002Ftrends.google.com\u002Ftrends\u002Fexplore?date=2016-04-10%202020-04-10&amp;q=Data%20Privacy\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cp\u003E[5]: Google Trends, “AI Ethics Search Interest (2016–2019).” Accessed on April 10, 2020. \u003Ca href=\"https:\u002F\u002Ftrends.google.com\u002Ftrends\u002Fexplore?date=2016-04-10%202019-04-10&amp;q=AI%20Ethics\"\u003Ehttps:\u002F\u002Ftrends.google.com\u002Ftrends\u002Fexplore?date=2016-04-10%202019-04-10&amp;q=AI%20Ethics\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cp\u003E[6]: Google Trends, “Privacy Software Search Interest (2016–2019).” Accessed on April 10, 2020. \u003Ca href=\"https:\u002F\u002Ftrends.google.com\u002Ftrends\u002Fexplore?date=2016-04-10%202019-04-10&amp;q=Privacy%20Software\"\u003Ehttps:\u002F\u002Ftrends.google.com\u002Ftrends\u002Fexplore?date=2016-04-10%202019-04-10&amp;q=Privacy%20Software\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cp\u003E[7]: Google Trends, “AI and ML Search Interest (2016–2019).” Accessed on April 10, 2020. \u003Ca href=\"https:\u002F\u002Ftrends.google.com\u002Ftrends\u002Fexplore?date=2016-04-10%202019-04-10&amp;q=Machine%20Learning,%2Fm%2F0mkz\"\u003Ehttps:\u002F\u002Ftrends.google.com\u002Ftrends\u002Fexplore?date=2016-04-10%202019-04-10&amp;q=Machine%20Learning,%2Fm%2F0mkz\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003Cp\u003E[8]: \u003Cem\u003EGeneral Data Protection Regulation\u003C\u002Fem\u003E, \u003Cem\u003EEuropean Parliament\u003C\u002Fem\u003E2016, 1–77.\u003C\u002Fp\u003E\u003Cp\u003E[9]: \u003Cem\u003EPersonal Information Protection and Electronic Documents Act\u003C\u002Fem\u003E, \u003Cem\u003ERevised Statutes of Canada\u003C\u002Fem\u003E 2000, 4–39.\u003C\u002Fp\u003E\u003Cp\u003E[10]: Bolukbasi, Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and Adam T. Kalai. “Man is to computer programmer as woman is to homemaker? debiasing word embeddings.” In \u003Cem\u003EAdvances in neural information processing systems\u003C\u002Fem\u003E, pp. 4350. 2016.\u003C\u002Fp\u003E\u003Cp\u003E[11]: Waldman, Ari Ezra. “Power, Process, and Automated Decision-Making.” \u003Cem\u003EFordham L. Rev.\u003C\u002Fem\u003E 88 (2019): 613.\u003C\u002Fp\u003E\u003Cp\u003E[12]: Kamarinou, Dimitra, Christopher Millard, and Jatinder Singh. “Machine Learning with Personal Data: Profiling, Decisions and the EU General Data Protection Regulation.” \u003Cem\u003EJournal of Machine Learning Research\u003C\u002Fem\u003E(2017): 1–7.\u003C\u002Fp\u003E\u003Cp\u003E[13]: Golea, Mostefa, and Mario Marchand. “A growth algorithm for neural network decision trees.” \u003Cem\u003EEPL (Europhysics Letters)\u003C\u002Fem\u003E 12, no. 3 (1990): 205.\u003C\u002Fp\u003E\u003Cp\u003E[14]: Kamarinou, Dimitra, Christopher Millard, and Jatinder Singh. “Machine Learning with Personal Data: Profiling, Decisions and the EU General Data Protection Regulation.” \u003Cem\u003EJournal of Machine Learning Research\u003C\u002Fem\u003E(2017): 1–7.\u003C\u002Fp\u003E\u003Cp\u003E[15]: Shintre, Saurabh, Kevin A. Roundy, and Jasjeet Dhaliwal. “Making Machine Learning Forget.” In \u003Cem\u003EAnnual Privacy Forum\u003C\u002Fem\u003E, pp. 72–83. Springer, Cham, 2019.\u003C\u002Fp\u003E"}}]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.e75a9efc.js"}catch(e){main="/client/legacy/client.e53be589.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@1.0.1.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> 